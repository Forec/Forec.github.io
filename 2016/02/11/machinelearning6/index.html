<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>机器学习笔记（Chapter 06 - 支持向量机） | Forec的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="支持向量机（Support Vector Machineds，SVM）是一个二类问题的分类器，实现方法多样，这里采用了序列最小优化（SMO）实现方法，并通过核函数拓展到非线性可分的SVM。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习笔记（Chapter 06 - 支持向量机）">
<meta property="og:url" content="http://forec.github.io/2016/02/11/machinelearning6/index.html">
<meta property="og:site_name" content="Forec的博客">
<meta property="og:description" content="支持向量机（Support Vector Machineds，SVM）是一个二类问题的分类器，实现方法多样，这里采用了序列最小优化（SMO）实现方法，并通过核函数拓展到非线性可分的SVM。">
<meta property="og:updated_time" content="2016-02-11T10:16:25.965Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习笔记（Chapter 06 - 支持向量机）">
<meta name="twitter:description" content="支持向量机（Support Vector Machineds，SVM）是一个二类问题的分类器，实现方法多样，这里采用了序列最小优化（SMO）实现方法，并通过核函数拓展到非线性可分的SVM。">
  
    <link rel="alternative" href="/atom.xml" title="Forec的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="http://7xktmz.com1.z0.glb.clouddn.com/%E5%A4%B4%E5%83%8F.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Forec</a></h1>
		</hgroup>

		
		<p class="header-subtitle">奋斗在Code Farm的在校生</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						<li>友情链接</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="http://github.com/forec" title="github">github</a>
					        
								<a class="zhihu" target="_blank" href="http://www.zhihu.com/people/forect" title="zhihu">zhihu</a>
					        
								<a class="mail" target="_blank" href="mailto://forec@bupt.edu.cn" title="mail">mail</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Algorithms/" style="font-size: 20px;">Algorithms</a> <a href="/tags/Data-Structures/" style="font-size: 15px;">Data-Structures</a> <a href="/tags/Mistakes/" style="font-size: 10px;">Mistakes</a> <a href="/tags/OS/" style="font-size: 10px;">OS</a> <a href="/tags/函数式编程/" style="font-size: 10px;">函数式编程</a> <a href="/tags/字符编码/" style="font-size: 10px;">字符编码</a> <a href="/tags/机器学习/" style="font-size: 12.5px;">机器学习</a> <a href="/tags/线程/" style="font-size: 10px;">线程</a> <a href="/tags/计算机组成与体系结构/" style="font-size: 17.5px;">计算机组成与体系结构</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://www.codewars.com/users/Forec">Forec的CodeWars</a>
			        
			        </div>
				</section>
				

				
				
				<section class="switch-part switch-part4">
				
					<div id="js-aboutme">就读于北京邮电大学，代码爱好者。近期自学机器学习。</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Forec</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="http://7xktmz.com1.z0.glb.clouddn.com/%E5%A4%B4%E5%83%8F.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Forec</h1>
			</hgroup>
			
			<p class="header-subtitle">奋斗在Code Farm的在校生</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="http://github.com/forec" title="github">github</a>
			        
						<a class="zhihu" target="_blank" href="http://www.zhihu.com/people/forect" title="zhihu">zhihu</a>
			        
						<a class="mail" target="_blank" href="mailto://forec@bupt.edu.cn" title="mail">mail</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-machinelearning6" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/02/11/machinelearning6/" class="article-date">
  	<time datetime="2016-02-11T10:05:05.000Z" itemprop="datePublished">2016-02-11</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习笔记（Chapter 06 - 支持向量机）
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/大数据/">大数据</a>
	</div>


        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>支持向量机（Support Vector Machineds，SVM）是一个二类问题的分类器，实现方法多样，这里采用了序列最小优化（SMO）实现方法，并通过核函数拓展到非线性可分的SVM。</p>
</blockquote>
<a id="more"></a>
<h1 id="SVM_u548C_u6700_u5927_u8FB9_u7F18_u8D85_u5E73_u9762"><a href="#SVM_u548C_u6700_u5927_u8FB9_u7F18_u8D85_u5E73_u9762" class="headerlink" title="SVM和最大边缘超平面"></a>SVM和最大边缘超平面</h1><ul>
<li>SVM的优缺点<ul>
<li>优点：泛化错误率低，计算开销不大撒，结果易解释</li>
<li>缺点：<strong>对参数调节和核函数的选择敏感</strong>，原始分类器不加修改情况下仅适用于处理二类问题</li>
<li>适用数值类型：数值型和标称型</li>
</ul>
</li>
<li>最大边缘超平面：在二维平面上分布的二类数值点，如果可以通过一条直线将两组不同类的数据分开，则这组数据<strong>线性可分</strong>。在假设数据线性可分的前提下，将数据集分开的直线被称为分隔超平面，如果数据分布在三位平面，那么分隔超平面就是二维的。如果数据集分布在N维空间，则分隔超平面是N-1维。如果<strong>数据点离分隔超平面越远，则最后的预测结果就越好</strong>。因为<strong>决策边界边缘较小的分类器对模型的过分拟合更加敏感，从而在未知的样本上的泛化能力很差</strong>。</li>
<li>支持向量：离分隔超平面最近的那些点，支持向量机决策只依赖支持向量。</li>
<li>寻找最大间隔：用向量的形式<code>W·X+b</code>书写分隔超平面不需要考虑空间维度，其中向量W和常量b描述了所给数据的分隔超平面。因此SVM需要寻找使分隔超平面成为最大边缘超平面的W和b。</li>
</ul>
<h1 id="u5206_u9694_u8D85_u5E73_u9762_u76EE_u6807_u51FD_u6570_u7684_u4F18_u5316"><a href="#u5206_u9694_u8D85_u5E73_u9762_u76EE_u6807_u51FD_u6570_u7684_u4F18_u5316" class="headerlink" title="分隔超平面目标函数的优化"></a>分隔超平面目标函数的优化</h1><ul>
<li>SVM工作原理：与Logistic回归类似，使用一个类似海维赛德阶跃函数的函数对所给数据的W·X+b的结果判定分类，如果结果大于0则输出+1，否则输出-1。使用+1和-1而不使用1和0的作用在于，可以通过一个统一公式来表示间隔或者数据点到分隔超平面的距离。</li>
<li><p>函数间隔和几何间隔：点到分隔超平面的函数间隔为<code>y*(wx+b)</code>，其中y是函数的类别标签（+1或-1）；点到超平面的几何间隔为<code>y*(wx+b)/||w||</code>。SVM使用几何间隔定义数据点和超平面的距离，因为如果使用函数间隔，则随着w的放大，（wx+b）的值也随之不断增大，此时最优化（最大化）距离无法确定w。《机器学习实战》对SVM的原理介绍很粗略，并且直接给出了最终的可以解决线性不可分情况的公式。《机器学习实战》中SMO之前的部分在<a href="http://www.cnblogs.com/v-July-v/archive/2012/06/01/2539022.html" target="_blank" rel="external">July的支持向量机通俗导论</a>的第一层有比较清楚的介绍。</p>
<blockquote>
<p>下面部分《机器学习实战》没有讲，在《数据挖掘导论》的5.5节。</p>
</blockquote>
</li>
<li><p><strong>边缘公式的优化</strong>：要最大化最小间隔几何距离，考虑离决策边界最近的数据，如果数据在决策边界上方，则wx+b的结果是正值，在下方为负值，我们可以<strong>固定一个因子，调整另一个因子来优化最大值</strong>。因此我们设置一个约束条件<code>y*(wx+b)&gt;=1</code>，这意味着所有的数据都在<code>wx+b&gt;=1</code>和<code>wx+b&lt;=-1</code>的范围内，距离超平面越远的店，其wx+b的绝对值就越大，只有支持向量才满足<code>y(wx+b)=1</code>的。我们选取两个数据点，一个在wx+b=1直线上，一个在wx+b=-1直线上，相减得到<code>w(x1-x2)=2</code>，注意w、x1和x2都是向量，所以d=x1-x2就代表着两点之间平行于超平面法线方向的距离。因此<code>d=2/||w||</code>。要让d最大，等价于让<code>f(w)=||w||^2/2</code>最小。因此，<strong>调整后的目标函数是f(w)，并且受到<code>y(wx+b)&gt;=1</code>的约束</strong>。目标函数是二次的，w和b是线性的，因此该问题是凸优化问题（凸函数一阶可微，二阶导衡非负），此时可以引入拉格朗日算子，并且根据KKT条件将不等式约束改为等式约束<code>y(wx+b)-1=0</code> ，变为最小化<code>Lp = ||w||^2/2 - ∑(λ(y(wx+b)-1)</code>，观察这个式子，我们限定λ&gt;=0。其一阶导数为0，得到w=∑λyx，∑λy=0。将这两个条件代入拉格朗日算子的公式中，就得到书中的最后的目标函数。</p>
</li>
<li>不可分情况的处理：如果有少数数据噪声，需要引入正值的松弛变量ε，修改约束条件为<code>y(wx+b)-(1-ε)&gt;=0</code>，假设直线wx+b=-1+ε经过数据点P，并且平行于决策边界，那么P到wx+b=-1的距离是ε/||w||。因此，ε提供了决策边界在训练样本P上的误差估计。同样，因为我们在决策边界上允许了一定的错误，可能导致误分许多的实例，所以<strong>对松弛变量很大的边界进行惩罚</strong>，修改后的目标函数为<code>f(w) = ||w||^2 /2 +C(∑ε)^k</code>，其中C和k是用户指定的参数，用于对误分的数据进行惩罚。假定k=1。这样修改后问题的拉格朗日函数多了一项<code>-∑με</code>，利用KKT条件约束，一阶导数为0，得到额外条件<code>μ+λ =C</code>，因此0&lt;=λ&lt;=C，配合<code>∑λy = 0</code>，这就是书中最终给出的约束公式。</li>
</ul>
<h2 id="SMO_u6C42_u89E3_u6700_u4F18_u5316_u95EE_u9898"><a href="#SMO_u6C42_u89E3_u6700_u4F18_u5316_u95EE_u9898" class="headerlink" title="SMO求解最优化问题"></a>SMO求解最优化问题</h2><blockquote>
<p>推荐<a href="http://www.cnblogs.com/jerrylead/archive/2011/03/18/1988419.html" target="_blank" rel="external">JerryLead博客中的支持向量机（五）SMO算法</a>。</p>
</blockquote>
<ul>
<li><p>SMO算法的目标是求出一系列α和b，这里的α就是上面约束条件中的λ（拉格朗日乘子），因为参考的博客和书中都用α，下面也都用α。只要求出了α，根据<code>w=∑αyx</code>，就能够求出w。工作原理是每次循环选择两个alpha进行优化处理，一旦找到一对可以优化的α，就增大其中一个，同时减少另外一个。这两个α的选择方法决定了SMO的效率和正确率。</p>
</li>
<li><p>SMO算法里的辅助函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">	dataMat = []; labelMat = []</span><br><span class="line">	fr = open(fileName)</span><br><span class="line">	<span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">		lineArr = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">		dataMat.append([float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])])</span><br><span class="line">		labelMat.append(float(lineArr[<span class="number">2</span>]))</span><br><span class="line">	<span class="keyword">return</span> dataMat, labelMat</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJrand</span><span class="params">(i, m)</span>:</span></span><br><span class="line">	j = i</span><br><span class="line">	<span class="keyword">while</span> (j == i):</span><br><span class="line">		j = int(random.uniform(<span class="number">0</span>,m))</span><br><span class="line">	<span class="keyword">return</span> j</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clipAlpha</span><span class="params">(aj, H, L)</span>:</span></span><br><span class="line">	<span class="keyword">if</span> aj &gt; H:</span><br><span class="line">		aj = H</span><br><span class="line">	<span class="keyword">if</span> L &gt; aj:</span><br><span class="line">		aj = L</span><br><span class="line">	<span class="keyword">return</span> aj</span><br></pre></td></tr></table></figure>
<ul>
<li><p>《机器学习实战》书中先给了简化版的SMO算法，每次先选定一个α，然后随机选取另一个α。如果所有向量都没有被优化，就增加迭代次数，直到达到要求的迭代次数。书中给出平均速度14.5s。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smoSimple</span><span class="params">(dataMatIn, classLabels, C, toler, maxIter)</span>:</span></span><br><span class="line">	dataMatrix = mat(dataMatIn); labelMat = mat(classLabels).transpose() <span class="comment"># m * 1</span></span><br><span class="line">	b = <span class="number">0</span>; m, n = shape(dataMatrix)</span><br><span class="line">	alphas = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">	iter = <span class="number">0</span></span><br><span class="line">	<span class="keyword">while</span> ( iter &lt; maxIter ):</span><br><span class="line">		alphaPairsChanged = <span class="number">0</span></span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">			fXi = float(multiply(alphas, labelMat).T *\</span><br><span class="line">				 (dataMatrix*dataMatrix[i,:].T)) + b  <span class="comment"># 1*m*(m*n)*(n*1) = 1 * 1</span></span><br><span class="line">			Ei = fXi - float(labelMat[i])	<span class="comment"># 1*1 - 1*1</span></span><br><span class="line">			<span class="keyword">if</span> ((labelMat[i] * Ei &lt; - toler) <span class="keyword">and</span> (alphas[i] &lt; C)) <span class="keyword">or</span> \</span><br><span class="line">				((labelMat[[i] * Ei &gt; toler]) <span class="keyword">and</span> (alphas[i] &gt; <span class="number">0</span>)):		<span class="comment"># vector i can be improved</span></span><br><span class="line">				j = selectJrand(i,m)	<span class="comment"># randomly choose another data vector</span></span><br><span class="line">				fXj = float(multiply(alphas, labelMat).T *\</span><br><span class="line">					(dataMatrix*dataMatrix[j,:].T)) + b</span><br><span class="line">				Ej = fXj - float(labelMat[j])</span><br><span class="line">				alphaIold = alphas[i].copy()</span><br><span class="line">				alphaJold = alphas[j].copy()</span><br><span class="line">				<span class="keyword">if</span> (labelMat[i] != labelMat[j]):</span><br><span class="line">					L = max(<span class="number">0</span>, alphas[j] - alphas[i])</span><br><span class="line">					H = min(C, C + alphas[j] - alphas[i])</span><br><span class="line">				<span class="keyword">else</span>:</span><br><span class="line">					L = max(<span class="number">0</span>, alphas[j] + alphas[i] - C)</span><br><span class="line">					H = min(C, alphas[j] + alphas[i])</span><br><span class="line">				<span class="keyword">if</span> L == H:</span><br><span class="line">					<span class="keyword">print</span> <span class="string">"LL==H"</span>; <span class="keyword">continue</span></span><br><span class="line">				eta = <span class="number">2.0</span> * dataMatrix[i,:] * dataMatrix[j,:].T - \</span><br><span class="line">					dataMatrix[i,:] * dataMatrix[i,:].T - \</span><br><span class="line">					dataMatrix[j,:] * dataMatrix[j,:].T</span><br><span class="line">				<span class="keyword">if</span> eta &gt;= <span class="number">0</span>: <span class="keyword">print</span> <span class="string">"eta&gt;=0"</span>; <span class="keyword">continue</span></span><br><span class="line">				alphas[j] -= labelMat[j] * (Ei -Ej) / eta</span><br><span class="line">				alphas[j] = clipAlpha(alphas[j], H, L)</span><br><span class="line">				<span class="keyword">if</span> (abs(alphas[j] - alphaJold) &lt; <span class="number">0.00001</span>):</span><br><span class="line">					<span class="keyword">print</span> <span class="string">"j not moving enough"</span>; <span class="keyword">continue</span></span><br><span class="line">				alphas[i] += labelMat[j] * labelMat[i] * \</span><br><span class="line">					(alphaJold - alphas[j])</span><br><span class="line">				b1 = b - Ei - labelMat[i] * (alphas[i] - alphaIold) *\</span><br><span class="line">					dataMatrix[i,:] * dataMatrix[i,:].T - \</span><br><span class="line">					labelMat[j] * (alphas[j] - alphaJold) * \</span><br><span class="line">					dataMatrix[i,:] * dataMatrix[j,:].T</span><br><span class="line">				b2 = b - Ej - labelMat[i] * (alphas[i] - alphaIold) *\</span><br><span class="line">					dataMatrix[i,:] * dataMatrix[j,:].T -\</span><br><span class="line">					labelMat[j] * (alphas[j] - alphaJold) * \</span><br><span class="line">					dataMatrix[j,:] * dataMatrix[j,:].T</span><br><span class="line">				<span class="keyword">if</span> ( <span class="number">0</span> &lt; alphas[i] ) <span class="keyword">and</span> ( C &gt; alphas[i] ): b = b1</span><br><span class="line">				<span class="keyword">elif</span> ( <span class="number">0</span> &lt; alphas[j] ) <span class="keyword">and</span> ( C &gt; alphas[j] ): b = b2</span><br><span class="line">				<span class="keyword">else</span>: b = (b1+b2)/<span class="number">2.0</span></span><br><span class="line">				alphaPairsChanged += <span class="number">1</span></span><br><span class="line">				<span class="keyword">print</span> <span class="string">"iter: %d i: %d, pairs changed %d"</span> % \</span><br><span class="line">					(iter, i ,alphaPairsChanged)</span><br><span class="line">		<span class="keyword">if</span> (alphaPairsChanged == <span class="number">0</span>): iter += <span class="number">1</span></span><br><span class="line">		<span class="keyword">else</span>: iter = <span class="number">0</span></span><br><span class="line">		<span class="keyword">print</span> <span class="string">"iteration number: %d"</span> % iter</span><br><span class="line">	<span class="keyword">return</span> b, alphas</span><br></pre></td></tr></table></figure>
</li>
<li><p>启发式选择方法：每次选择α时，优先选择样本前面系数0&lt;α&lt;C的α作优化，因为在界上（α为0或C）的样例对应的α一般不会更改。这种启发式搜索方法是选择第一个α用的，只要选择出来的两个α中有一个违背了KKT条件，那么目标函数在一步迭代后值会减小。违背KKT条件不代表0&lt;α&lt;C，在界上也有可能会违背。因此<strong>在给定初始值α1=0后，先对所有样例进行循环，循环中碰到违背KKT条件的（不管界上还是界内）都进行迭代更新。等这轮过后，如果没有收敛，第二轮就只针对的样例进行迭代更新</strong>。在第一个α选择后，第二个α也使用启发式方法选择，<strong>第二个α的迭代步长大致正比于|E1-E2|，选择第二个α能够最大化|E1-E2|</strong>。即当E1为正时选择负的绝对值最大的E2，反之，选择正值最大的E2。最后的收敛条件是在界内（0&lt;α&lt;C）的样例都能够遵循KKT条件，且其对应的α只在极小的范围内变动。 </p>
</li>
<li>完整的Platt SMO算法，书上数据平均时间0.78秒。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">optStruct</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,dataMatIn, classLabels, C, toler)</span>:</span>  <span class="comment"># Initialize the structure with the parameters </span></span><br><span class="line">        self.X = dataMatIn</span><br><span class="line">        self.labelMat = classLabels</span><br><span class="line">        self.C = C</span><br><span class="line">        self.tol = toler</span><br><span class="line">        self.m = shape(dataMatIn)[<span class="number">0</span>]</span><br><span class="line">        self.alphas = mat(zeros((self.m,<span class="number">1</span>)))</span><br><span class="line">        self.b = <span class="number">0</span></span><br><span class="line">        self.eCache = mat(zeros((self.m,<span class="number">2</span>))) <span class="comment">#first column is valid flag</span></span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcEk</span><span class="params">(oS, k)</span>:</span></span><br><span class="line">    fXk = float(multiply(oS.alphas,oS.labelMat).T*(oS.X*oS.X[k,:].T)) + oS.b</span><br><span class="line">    Ek = fXk - float(oS.labelMat[k])</span><br><span class="line">    <span class="keyword">return</span> Ek</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJK</span><span class="params">(i, oS, Ei)</span>:</span>         <span class="comment">#this is the second choice -heurstic, and calcs Ej</span></span><br><span class="line">    maxK = -<span class="number">1</span>; maxDeltaE = <span class="number">0</span>; Ej = <span class="number">0</span></span><br><span class="line">    oS.eCache[i] = [<span class="number">1</span>,Ei]  <span class="comment">#set valid #choose the alpha that gives the maximum delta E</span></span><br><span class="line">    validEcacheList = nonzero(oS.eCache[:,<span class="number">0</span>].A)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> (len(validEcacheList)) &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> validEcacheList:   <span class="comment">#loop through valid Ecache values and find the one that maximizes delta E</span></span><br><span class="line">            <span class="keyword">if</span> k == i: <span class="keyword">continue</span> <span class="comment">#don't calc for i, waste of time</span></span><br><span class="line">            Ek = calcEk(oS, k)</span><br><span class="line">            deltaE = abs(Ei - Ek)</span><br><span class="line">            <span class="keyword">if</span> (deltaE &gt; maxDeltaE):</span><br><span class="line">                maxK = k; maxDeltaE = deltaE; Ej = Ek</span><br><span class="line">        <span class="keyword">return</span> maxK, Ej</span><br><span class="line">    <span class="keyword">else</span>:   <span class="comment">#in this case (first time around) we don't have any valid eCache values</span></span><br><span class="line">        j = selectJrand(i, oS.m)</span><br><span class="line">        Ej = calcEk(oS, j)</span><br><span class="line">    <span class="keyword">return</span> j, Ej</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateEkK</span><span class="params">(oS, k)</span>:</span><span class="comment">#after any alpha has changed update the new value in the cache</span></span><br><span class="line">    Ek = calcEk(oS, k)</span><br><span class="line">    oS.eCache[k] = [<span class="number">1</span>,Ek]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">innerL</span><span class="params">(i, oS)</span>:</span></span><br><span class="line">    Ei = calcEk(oS, i)</span><br><span class="line">    <span class="keyword">if</span> ((oS.labelMat[i]*Ei &lt; -oS.tol) <span class="keyword">and</span> (oS.alphas[i] &lt; oS.C)) <span class="keyword">or</span> ((oS.labelMat[i]*Ei &gt; oS.tol) <span class="keyword">and</span> (oS.alphas[i] &gt; <span class="number">0</span>)):</span><br><span class="line">        j,Ej = selectJ(i, oS, Ei) <span class="comment">#this has been changed from selectJrand</span></span><br><span class="line">        alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy();</span><br><span class="line">        <span class="keyword">if</span> (oS.labelMat[i] != oS.labelMat[j]):</span><br><span class="line">            L = max(<span class="number">0</span>, oS.alphas[j] - oS.alphas[i])</span><br><span class="line">            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            L = max(<span class="number">0</span>, oS.alphas[j] + oS.alphas[i] - oS.C)</span><br><span class="line">            H = min(oS.C, oS.alphas[j] + oS.alphas[i])</span><br><span class="line">        <span class="keyword">if</span> L==H: <span class="keyword">print</span> <span class="string">"L==H"</span>; <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        eta = <span class="number">2.0</span> * oS.X[i,:]*oS.X[j,:].T - oS.X[i,:]*oS.X[i,:].T - oS.X[j,:]*oS.X[j,:].T</span><br><span class="line">        <span class="keyword">if</span> eta &gt;= <span class="number">0</span>: <span class="keyword">print</span> <span class="string">"eta&gt;=0"</span>; <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta</span><br><span class="line">        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)</span><br><span class="line">        updateEk(oS, j) <span class="comment">#added this for the Ecache</span></span><br><span class="line">        <span class="keyword">if</span> (abs(oS.alphas[j] - alphaJold) &lt; <span class="number">0.00001</span>): <span class="keyword">print</span> <span class="string">"j not moving enough"</span>; <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])<span class="comment">#update i by the same amount as j</span></span><br><span class="line">        updateEk(oS, i) <span class="comment">#added this for the Ecache                    #the update is in the oppostie direction</span></span><br><span class="line">        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[i,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[i,:]*oS.X[j,:].T</span><br><span class="line">        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[j,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[j,:]*oS.X[j,:].T</span><br><span class="line">        <span class="keyword">if</span> (<span class="number">0</span> &lt; oS.alphas[i]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[i]): oS.b = b1</span><br><span class="line">        <span class="keyword">elif</span> (<span class="number">0</span> &lt; oS.alphas[j]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[j]): oS.b = b2</span><br><span class="line">        <span class="keyword">else</span>: oS.b = (b1 + b2)/<span class="number">2.0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>下面是外循环代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smoP</span><span class="params">(dataMatIn, classLabels, C, toler, maxIter)</span>:</span>    <span class="comment">#full Platt SMO</span></span><br><span class="line">    oS = optStruct(mat(dataMatIn),mat(classLabels).transpose(),C,toler)</span><br><span class="line">    iter = <span class="number">0</span></span><br><span class="line">    entireSet = <span class="keyword">True</span>; alphaPairsChanged = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (iter &lt; maxIter) <span class="keyword">and</span> ((alphaPairsChanged &gt; <span class="number">0</span>) <span class="keyword">or</span> (entireSet)):</span><br><span class="line">        alphaPairsChanged = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> entireSet:   <span class="comment">#go over all</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(oS.m):        </span><br><span class="line">                alphaPairsChanged += innerL(i,oS)</span><br><span class="line">                <span class="keyword">print</span> <span class="string">"fullSet, iter: %d i:%d, pairs changed %d"</span> % (iter,i,alphaPairsChanged)</span><br><span class="line">            iter += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:<span class="comment">#go over non-bound (railed) alphas</span></span><br><span class="line">            nonBoundIs = nonzero((oS.alphas.A &gt; <span class="number">0</span>) * (oS.alphas.A &lt; C))[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> nonBoundIs:</span><br><span class="line">                alphaPairsChanged += innerL(i,oS)</span><br><span class="line">                <span class="keyword">print</span> <span class="string">"non-bound, iter: %d i:%d, pairs changed %d"</span> % (iter,i,alphaPairsChanged)</span><br><span class="line">            iter += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> entireSet: entireSet = <span class="keyword">False</span> <span class="comment">#toggle entire set loop</span></span><br><span class="line">        <span class="keyword">elif</span> (alphaPairsChanged == <span class="number">0</span>): entireSet = <span class="keyword">True</span>  </span><br><span class="line">        <span class="keyword">print</span> <span class="string">"iteration number: %d"</span> % iter</span><br><span class="line">    <span class="keyword">return</span> oS.b,oS.alphas</span><br></pre></td></tr></table></figure></p>
<p>下面是求W和分类函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcWs</span><span class="params">(alphas, dataArr, classLabels)</span>:</span> </span><br><span class="line">	X = mat(dataArr); labelMat = mat(classLabels).transpose()</span><br><span class="line">	m, n = shape(X)</span><br><span class="line">	w = zeros((n,<span class="number">1</span>))	<span class="comment"># n*1</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">		w += multiply(alphas[i] * labelMat[i], X[i,:].T)	<span class="comment"># n*1*1 (1*n)^T</span></span><br><span class="line">	<span class="keyword">return</span> w</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classified</span><span class="params">(dat, ws, b)</span>:</span></span><br><span class="line">	<span class="keyword">if</span> dat * mat(ws) + b &gt; <span class="number">0</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<h1 id="u6838_u51FD_u6570"><a href="#u6838_u51FD_u6570" class="headerlink" title="核函数"></a>核函数</h1><blockquote>
<p>来自《数据挖掘导论》，并参考<a href="https://www.zhihu.com/question/24627666" target="_blank" rel="external">知乎上关于机器学习中核函数的讨论</a></p>
</blockquote>
<ul>
<li><p>径向基函数（RBF）：是一个采用向量作为自变量的函数，能够基于向量距离运算输出一个标量。</p>
</li>
<li><p>核函数和SVM是两个正交的概念，通过核函数可以将当前维度无法线性划分的数据转移到高维（无穷维度）。SVM核的变换后空间也称为<strong>再生核希尔伯特空间（RKHS）</strong>，使用核函数计算点积开销更小，并且计算在原空间进行，无须担心维灾难问题。</p>
</li>
<li>Mercer定理：对非线性SVM使用的核函数的主要要求是，必须存在一个相应的变换，使得计算一对向量的核函数等价于在变换后的空间中计算这对向量的点积。核函数K可以表示为<code>K(u, v) = Φ(u)Φ(v)</code>，当且仅当对于任意满足<code>∫g(x)^2dx</code>为有限值得函数g(x)，则<code>∫K(x,y)g(x)g(y)dxdy &gt;= 0</code>。满足这个定理的核函数称为正定核函数。例如<code>K(x,y) = (x·y+1)^p</code>，<code>K(x,y) = e^(-(|x-y|^2)/2σ^2))</code>，<code>K(x,y) = tanh(ky·y - δ)</code>。</li>
<li>在测试中使用核函数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kernelTrans</span><span class="params">(X, A, kTup)</span>:</span></span><br><span class="line">	m, n = shape(X)</span><br><span class="line">	K = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">	<span class="keyword">if</span> kTup[<span class="number">0</span>] == <span class="string">'lin'</span>: K = X*A.T</span><br><span class="line">	<span class="keyword">elif</span> kTup[<span class="number">0</span>] == <span class="string">'rbf'</span>:</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(m):</span><br><span class="line">			deltaRow = X[j,:] - A</span><br><span class="line">			K[j] = deltaRow * deltaRow.T</span><br><span class="line">		K = exp(K / (-<span class="number">1</span>*kTup[<span class="number">1</span>]**<span class="number">2</span>))</span><br><span class="line">	<span class="keyword">else</span>: <span class="keyword">raise</span> NameError(<span class="string">"Houston We Have a Problem -- \</span><br><span class="line">		That kernel is not recognized"</span>)</span><br><span class="line">	<span class="keyword">return</span> K</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>下面是测试函数，需要对函数innerL和calcEk和类optStruct做一定修改。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testRbf</span><span class="params">(k1=<span class="number">1.3</span>)</span>:</span></span><br><span class="line">	dataArr, labelArr = loadDataSet(<span class="string">'testSetRBF.txt'</span>)</span><br><span class="line">	b, alphas = smoP(dataArr, labelArr, <span class="number">200</span>, <span class="number">0.0001</span>, <span class="number">10000</span>, (<span class="string">'rbf'</span>,k1))</span><br><span class="line">	datMat = mat(dataArr); labelMat = mat(labelArr).transpose()</span><br><span class="line">	svInd = nonzero(alphas.A &gt; <span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">	sVs = datMat[svInd]</span><br><span class="line">	labelSV = labelMat[svInd]</span><br><span class="line">	<span class="keyword">print</span> <span class="string">"there are %d Support Vectors"</span> % shape(sVs)[<span class="number">0</span>]</span><br><span class="line">	m, n = shape(datMat)</span><br><span class="line">	errorCount = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">		kernelEval = kernelTrans(sVs, datMat[i,:], (<span class="string">'rbf'</span>,k1))</span><br><span class="line">		predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b</span><br><span class="line">		<span class="keyword">if</span> sign(predict) != sign(labelArr[i]) : errorCount += <span class="number">1</span></span><br><span class="line">	<span class="keyword">print</span> <span class="string">"the training error rate is %f"</span> % (float(errorCount)/m) </span><br><span class="line">	dataArr, labelArr = loadDataSet(<span class="string">'testSetRBF2.txt'</span>)</span><br><span class="line">	datMat = mat(dataArr); labelMat = mat(labelArr).transpose()</span><br><span class="line">	m, n = shape(datMat)</span><br><span class="line">	errorCount = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">		kernelEval = kernelTrans(sVs, datMat[i,:], (<span class="string">'rbf'</span>,k1))</span><br><span class="line">		predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b</span><br><span class="line">		<span class="keyword">if</span> sign(predict) != sign(labelArr[i]) : errorCount += <span class="number">1</span></span><br><span class="line">	<span class="keyword">print</span> <span class="string">"the test error rate is %f"</span> % (float(errorCount)/m)</span><br></pre></td></tr></table></figure></p>
<p>修改的地方<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">innerL</span><span class="params">()</span>:</span></span><br><span class="line">    ···</span><br><span class="line">    eta = <span class="number">2.0</span> * oS.K[i,j] - oS.K[i,i] - oS.K[j,j]</span><br><span class="line">    ···</span><br><span class="line">    b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[i,i] -\</span><br><span class="line">			oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.K[i,j]</span><br><span class="line">		b2 = oS.b - Ej - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[i,j] - \</span><br><span class="line">			oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.K[j,j]</span><br><span class="line">	···</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcEk</span><span class="params">(oS, k)</span>:</span></span><br><span class="line">	fXk = float(multiply(oS.alphas, oS.labelMat).T * oS.K[:,k] + oS.b)</span><br><span class="line">	Ek = fXk - float(oS.labelMat[k])</span><br><span class="line">	<span class="keyword">return</span> Ek</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">```<span class="class"><span class="keyword">class</span> <span class="title">optStruct</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dataMatIn, classLabels, C, toler, kTup)</span>:</span></span><br><span class="line">		self.X = dataMatIn</span><br><span class="line">		self.labelMat = classLabels</span><br><span class="line">		self.C = C</span><br><span class="line">		self.tol = toler</span><br><span class="line">		self.m = shape(dataMatIn)[<span class="number">0</span>]</span><br><span class="line">		self.alphas = mat(zeros((self.m,<span class="number">1</span>)))</span><br><span class="line">		self.b = <span class="number">0</span></span><br><span class="line">		self.eCache = mat(zeros((self.m,<span class="number">2</span>)))</span><br><span class="line">		self.K = mat(zeros((self.m, self.m)))</span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> range(self.m):</span><br><span class="line">			self.K[:,i] = kernelTrans(self.X, self.X[i,:], kTup)</span><br></pre></td></tr></table></figure>
<h2 id="kNN_u624B_u5199_u95EE_u9898_u56DE_u987E"><a href="#kNN_u624B_u5199_u95EE_u9898_u56DE_u987E" class="headerlink" title="kNN手写问题回顾"></a>kNN手写问题回顾</h2><ul>
<li><p>SVM是二类分类器，将非9的数字判为-1，否则判为1。</p>
</li>
<li><p>Code - testDigits - svmMLiA.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img2vector</span><span class="params">(filename)</span>:</span></span><br><span class="line">    returnVect = zeros((<span class="number">1</span>,<span class="number">1024</span>))</span><br><span class="line">    fr = open(filename)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">32</span>):</span><br><span class="line">        lineStr = fr.readline()</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">32</span>):</span><br><span class="line">            returnVect[<span class="number">0</span>,<span class="number">32</span>*i+j] = int(lineStr[j])</span><br><span class="line">    <span class="keyword">return</span> returnVect</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadImages</span><span class="params">(dirName)</span>:</span></span><br><span class="line">    <span class="keyword">from</span> os <span class="keyword">import</span> listdir</span><br><span class="line">    hwLabels = []</span><br><span class="line">    trainingFileList = listdir(dirName)           <span class="comment">#load the training set</span></span><br><span class="line">    m = len(trainingFileList)</span><br><span class="line">    trainingMat = zeros((m,<span class="number">1024</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        fileNameStr = trainingFileList[i]</span><br><span class="line">        fileStr = fileNameStr.split(<span class="string">'.'</span>)[<span class="number">0</span>]     <span class="comment">#take off .txt</span></span><br><span class="line">        classNumStr = int(fileStr.split(<span class="string">'_'</span>)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> classNumStr == <span class="number">9</span>: hwLabels.append(-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>: hwLabels.append(<span class="number">1</span>)</span><br><span class="line">        trainingMat[i,:] = img2vector(<span class="string">'%s/%s'</span> % (dirName, fileNameStr))</span><br><span class="line">    <span class="keyword">return</span> trainingMat, hwLabels</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testDigits</span><span class="params">(kTup=<span class="params">(<span class="string">'rbf'</span>, <span class="number">10</span>)</span>)</span>:</span></span><br><span class="line">    dataArr,labelArr = loadImages(<span class="string">'trainingDigits'</span>)</span><br><span class="line">    b,alphas = smoP(dataArr, labelArr, <span class="number">200</span>, <span class="number">0.0001</span>, <span class="number">10000</span>, kTup)</span><br><span class="line">    datMat=mat(dataArr); labelMat = mat(labelArr).transpose()</span><br><span class="line">    svInd=nonzero(alphas.A&gt;<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">    sVs=datMat[svInd] </span><br><span class="line">    labelSV = labelMat[svInd];</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"there are %d Support Vectors"</span> % shape(sVs)[<span class="number">0</span>]</span><br><span class="line">    m,n = shape(datMat)</span><br><span class="line">    errorCount = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        kernelEval = kernelTrans(sVs,datMat[i,:],kTup)</span><br><span class="line">        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b</span><br><span class="line">        <span class="keyword">if</span> sign(predict)!=sign(labelArr[i]): errorCount += <span class="number">1</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"the training error rate is: %f"</span> % (float(errorCount)/m)</span><br><span class="line">    dataArr,labelArr = loadImages(<span class="string">'testDigits'</span>)</span><br><span class="line">    errorCount = <span class="number">0</span></span><br><span class="line">    datMat=mat(dataArr); labelMat = mat(labelArr).transpose()</span><br><span class="line">    m,n = shape(datMat)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        kernelEval = kernelTrans(sVs,datMat[i,:],kTup)</span><br><span class="line">        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b</span><br><span class="line">        <span class="keyword">if</span> sign(predict)!=sign(labelArr[i]): errorCount += <span class="number">1</span>    </span><br><span class="line">    <span class="keyword">print</span> <span class="string">"the test error rate is: %f"</span> % (float(errorCount)/m)</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改径向基核函数的参数σ，观察错误率。σ下降，则训练错误率降低，测试错误率上升。最小的训练错误率并不对应于最小的向量支持数目。另外线性和函数的效果并不很糟糕，可以牺牲线性核函数的错误率来换取分类速度的提高。</p>
</li>
</ul>
<h1 id="u591A_u7C7B_u5206_u7C7B_u95EE_u9898"><a href="#u591A_u7C7B_u5206_u7C7B_u95EE_u9898" class="headerlink" title="多类分类问题"></a>多类分类问题</h1><ul>
<li>第一种方法将多类问题分解为K个二类问题，对于类别yi，属于类别yi的为一类，不属于yi的为另一类。此方法称为一对其他（1-r）方法。</li>
<li>第二种方法为一对一（1-1）方法，构建K(K-1)/2个分类器，没一个分类器用来区分一对类(yi,yj)，此时忽略其他类的样本。</li>
<li>以上两种方法都使用二类分类器的组合预测，并投票表决，票数多的分类为最终分类。这种方法可能导致不同类的平局。</li>
<li>纠错输出编码：1-r和1-1方法都对二元分类的错误太敏感。可以参考海明编码，为每个类别分配一个码字，码字的每个二进制位训练一个二元分类器。</li>
</ul>
<h1 id="u652F_u6301_u5411_u91CF_u673A_u603B_u7ED3"><a href="#u652F_u6301_u5411_u91CF_u673A_u603B_u7ED3" class="headerlink" title="支持向量机总结"></a>支持向量机总结</h1><blockquote>
<p>支持向量机是一种二类分类器，通过求解一个二次优化问题来最大化分类间隔。通过SMO算法每次优化两个α可以提升SVM的训练速度。核函数可以从一个低维空间的非线性数据映射到一个高维空间的线性数据i，此部分可以参考知乎。</p>
<p>SVM问题可以表示为凸优化问题，利用已知的有效算法发现目标函数的全局最小值。通过最大化决策边界的边缘来控制模型的能力，用户必须提供其他参数，如核函数类型、松弛变量带来的惩罚C。</p>
</blockquote>
<hr>
<p>参考文献： 《机器学习实战 - 美Peter Harrington》、《数据挖掘导论 - 美Pang-Ning Tan等》</p>
<p>参考的文章等：<a href="http://www.cnblogs.com/v-July-v/archive/2012/06/01/2539022.html" target="_blank" rel="external">July的文章</a>，<a href="http://www.cnblogs.com/jerrylead/archive/2011/03/18/1988419.html" target="_blank" rel="external">JerryLead的文章</a>，<a href="https://www.zhihu.com/question/24627666" target="_blank" rel="external">王赟 Maigo等在知乎上的答案</a></p>
<p>原创作品，允许转载，转载时无需告知，但请务必以超链接形式标明文章<a href="http://forec.github.io/2016/02/11/machinelearning6/">原始出处</a>(<a href="http://forec.github.io/2016/02/11/machinelearning6/">http://forec.github.io/2016/02/11/machinelearning6/</a>) 、作者信息（<a href="http://forec.github.io/">Forec</a>）和本声明。</p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/02/13/functional-thinking/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          《函数式编程思维》笔记
        
      </div>
    </a>
  
  
    <a href="/2016/02/09/machinelearning5/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">机器学习笔记（Chapter 05 - Logistic回归）</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share_jia">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到: &nbsp; </span>
		<a class="jiathis_button_facebook"></a> 
    <a class="jiathis_button_twitter"></a>
    <a class="jiathis_button_plus"></a> 
    <a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>






<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="machinelearning6" data-title="机器学习笔记（Chapter 06 - 支持向量机）" data-url="http://forec.github.io/2016/02/11/machinelearning6/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"forec"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 Forec
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>