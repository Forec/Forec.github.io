<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习笔记（Chapter 13 - PCA简化） | Forec&#39;s Notes</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="在低维下，数据更容易进行处理，其相关特征可能在数据中明确显示出来。PCA是降维技术中最广泛的一种。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习笔记（Chapter 13 - PCA简化）">
<meta property="og:url" content="http://forec.github.io/2016/02/25/machinelearning13/index.html">
<meta property="og:site_name" content="Forec's Notes">
<meta property="og:description" content="在低维下，数据更容易进行处理，其相关特征可能在数据中明确显示出来。PCA是降维技术中最广泛的一种。">
<meta property="og:image" content="http://7xktmz.com1.z0.glb.clouddn.com/pca%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE.png">
<meta property="og:image" content="http://7xktmz.com1.z0.glb.clouddn.com/pca%E9%99%8D%E7%BB%B42.png">
<meta property="og:image" content="http://7xktmz.com1.z0.glb.clouddn.com/pca%E9%99%8D%E7%BB%B4.png">
<meta property="og:image" content="http://7xktmz.com1.z0.glb.clouddn.com/pca%E6%96%B9%E5%B7%AE%E5%8D%A0%E6%AF%94.png">
<meta property="og:updated_time" content="2016-10-03T15:36:56.881Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习笔记（Chapter 13 - PCA简化）">
<meta name="twitter:description" content="在低维下，数据更容易进行处理，其相关特征可能在数据中明确显示出来。PCA是降维技术中最广泛的一种。">
  
    <link rel="alternative" href="/atom.xml" title="Forec&#39;s Notes" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Forec&#39;s Notes</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://forec.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-machinelearning13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/25/machinelearning13/" class="article-date">
  <time datetime="2016-02-25T04:15:43.000Z" itemprop="datePublished">2016-02-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/大数据/">大数据</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习笔记（Chapter 13 - PCA简化）
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>在低维下，数据更容易进行处理，其相关特征可能在数据中明确显示出来。PCA是降维技术中最广泛的一种。</p>
</blockquote>
<a id="more"></a>
<h1 id="降维技术"><a href="#降维技术" class="headerlink" title="降维技术"></a>降维技术</h1><ul>
<li>数据往往拥有超出显示能力的更多特征，简化数据不止使得数据容易显示，同时降低算法计算开销、去除噪声、使得结果易懂。</li>
<li>主成分分析（Principal Component Analysis，PCA）将数据从原来的坐标系转移到新的坐标系，新坐标系的选择由数据本身决定，新坐标系的第一个坐标轴是原始数据中方差最大的方向，新坐标系的第二个坐标轴和第一个坐标轴正交、并且具有最大方差。该过程一直重复，次数为原始数据中维度。大部分方差都包含在前面几个新坐标轴中，因此可以忽略剩下的坐标轴。</li>
<li>因子分析（Factor Analysis）假设观察数据的生成中有一些观察不到的隐变量，即观察数据是由这些隐变量和某些噪声的线性组合，那么隐变量的数据可能比观察数据的数目少，找到隐变量就可以实现数据的降维。</li>
<li>独立成分分析（Independent Component Analysis，ICA）假设数据从N个数据源生成，类似因子分析，假设这些数据源之间在统计上相互独立，如果数据源数目少于观察数据数目，就实现降维过程。</li>
</ul>
<h1 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h1><ul>
<li>PCA可以降低数据复杂性，识别最重要的多个特征，但有时不一定需要，并且可能损失有用信息。适用于数值型数据。</li>
<li>对于下图的数据，要找出一条直线尽可能覆盖这些点，第一条坐标轴旋转到最大方差的方向，数据的最大方差给出了数据的最重要的信息。在选择了覆盖数据最大差异性的坐标轴之后，选择第二条坐标轴与第一条正交。<img src="http://7xktmz.com1.z0.glb.clouddn.com/pca%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE.png" width="400px">在下面的示例中，只需要一维信息，另一维信息只是对分类缺乏贡献的噪声数据。可以采用决策树，也可以使用SVM获得更好的分类间隔，但是分类超平面很难解释。PCA降维可以同时获得SVM和决策树的优点。<img src="http://7xktmz.com1.z0.glb.clouddn.com/pca%E9%99%8D%E7%BB%B42.png" width="400px"></li>
<li><p>PCA过程实现：第一个主成分从数据差异性最大的方向获取，可以通过数据集的<a href="http://pinkyjie.com/2010/08/31/covariance/" target="_blank" rel="external">协方差矩阵 Convariance</a>和<a href="http://www.tongji.edu.cn/~math/xxds/kcja/kcja_b/5-2.htm" target="_blank" rel="external">特征值</a>分析求得。下面pca函数的流程为，首先去除平均值，之后计算协方差矩阵<code>cov</code>，计算协方差矩阵的特征值和特征向量<code>linalg.eig</code>，将特征值从大到小排序，保留对应的最上面的N个特征向量，最后将数据转换到上述N个特征向量构建的新空间中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName, delim = <span class="string">'\t'</span>)</span>:</span></span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    stringArr = [line.strip().split(delim) <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines()]</span><br><span class="line">    datArr = [map(float, line) <span class="keyword">for</span> line <span class="keyword">in</span> stringArr]</span><br><span class="line">    <span class="keyword">return</span> mat(datArr)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pca</span><span class="params">(dataMat, topNfeat = <span class="number">999999</span>)</span>:</span></span><br><span class="line">    meanVals = mean(dataMat, axis = <span class="number">0</span>)</span><br><span class="line">    meanRemoved = dataMat - meanVals</span><br><span class="line">    covMat = cov(meanRemoved, rowvar = <span class="number">0</span>)   <span class="comment"># n*n</span></span><br><span class="line">    eigVals, eigVects = linalg.eig(mat(covMat))</span><br><span class="line">        <span class="comment"># 1*n, n*n</span></span><br><span class="line">    eigValInd = argsort(eigVals)</span><br><span class="line">    eigValInd = eigValInd[:-(topNfeat+<span class="number">1</span>):-<span class="number">1</span>]</span><br><span class="line">    redEigVects = eigVects[:,eigValInd]</span><br><span class="line">    lowDDataMat = meanRemoved * redEigVects</span><br><span class="line">    reconMat = (lowDDataMat * redEigVects.T) + meanVals</span><br><span class="line">    <span class="keyword">return</span> lowDDataMat, reconMat</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行示例如下，下图是构造出的第一主成分。<img src="http://7xktmz.com1.z0.glb.clouddn.com/pca%E9%99%8D%E7%BB%B4.png" width="400px"><br></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="prompt">&gt;&gt;&gt; </span>dataMat = pca.loadDataSet(<span class="string">'testSet.txt'</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>lowDMat, reconMat = pca.pca(dataMat, <span class="number">1</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>shape(lowDMat)</span><br><span class="line">(<span class="number">1000</span>, <span class="number">1</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>fig = plt.figure()</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>ax.scatter(dataMat[:,<span class="number">0</span>].flatten().A[<span class="number">0</span>], dataMat[:,<span class="number">1</span>].flatten().A[<span class="number">0</span>],\</span><br><span class="line">        marker = <span class="string">'^'</span>, s = <span class="number">90</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>ax.scatter(reconMat[:,<span class="number">0</span>].flatten().A[<span class="number">0</span>], reconMat[:,<span class="number">1</span>].flatten().A[<span class="number">0</span>],\</span><br><span class="line">        marker = <span class="string">'o'</span>, s = <span class="number">50</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>plt.show()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="利用PCA对半导体制造数据降维"><a href="#利用PCA对半导体制造数据降维" class="headerlink" title="利用PCA对半导体制造数据降维"></a>利用PCA对半导体制造数据降维</h1><ul>
<li><p><a href="http://archive.ics.uci.edu/ml/machine-learning-databases/secom/" target="_blank" rel="external">数据集</a>来自UCI机器学习数据库，包含590个特征，其中几乎所有样本都存在特征缺失，用NaN表示，通过replaceNanWithMean将缺失的NaN数据用其他样本的相同特征值平均值填充。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">replaceNanWithMean</span><span class="params">()</span>:</span></span><br><span class="line">    datMat = loadDataSet(<span class="string">'secom.data'</span>, <span class="string">' '</span>)</span><br><span class="line">    numFeat = shape(datMat)[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeat):</span><br><span class="line">        meanVal = mean(datMat[nonzero(~isnan(datMat[:,i].A))[<span class="number">0</span>], i])</span><br><span class="line">        datMat[nonzero(isnan(datMat[:,i].A))[<span class="number">0</span>], i] = meanVal</span><br><span class="line">    <span class="keyword">return</span> datMat</span><br></pre></td></tr></table></figure>
</li>
<li><p>从特征值可以看出，有超过20%特征值为0，这些特征都是其他特征的副本。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="prompt">&gt;&gt;&gt; </span>dataMat = pca.replaceNanWithMean()</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>meanVals = mean(dataMat, axis=<span class="number">0</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>meanRemoved = dataMat - meanVals</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>covMat = cov(meanRemoved, rowvar=<span class="number">0</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>eigVals, eigVects = linalg.eig(mat(covMat))</span><br><span class="line">array([  <span class="number">5.34151979e+07</span>,   <span class="number">2.17466719e+07</span>,   <span class="number">8.24837662e+06</span>,</span><br><span class="line">         <span class="number">2.07388086e+06</span>,   <span class="number">1.31540439e+06</span>,   <span class="number">4.67693557e+05</span>,</span><br><span class="line">         <span class="number">2.90863555e+05</span>,   <span class="number">2.83668601e+05</span>,   <span class="number">2.37155830e+05</span>,</span><br><span class="line">         <span class="number">2.08513836e+05</span>,   <span class="number">1.96098849e+05</span>,   <span class="number">1.86856549e+05</span>,</span><br><span class="line">         ......</span><br><span class="line">         <span class="number">0.00000000e+00</span>,   <span class="number">0.00000000e+00</span>,   <span class="number">0.00000000e+00</span>,</span><br><span class="line">         <span class="number">0.00000000e+00</span>,   <span class="number">0.00000000e+00</span>,   <span class="number">0.00000000e+00</span>,</span><br><span class="line">         <span class="number">0.00000000e+00</span>,   <span class="number">0.00000000e+00</span>,   <span class="number">0.00000000e+00</span>,</span><br></pre></td></tr></table></figure>
</li>
<li><p>下图是前二十个主成分占总方差的百分比，大部分方差都包含在前面几个主成分中，前6个特征覆盖了96.8%的方差。因此可以将590个特征缩减到这6个特征。现实中我们无法精确知道所需要的主成分数目，必须通过实验取不同值来确定。<img src="http://7xktmz.com1.z0.glb.clouddn.com/pca%E6%96%B9%E5%B7%AE%E5%8D%A0%E6%AF%94.png" width="400px"></p>
</li>
</ul>
<h1 id="PCA总结"><a href="#PCA总结" class="headerlink" title="PCA总结"></a>PCA总结</h1><blockquote>
<p>降维技术使数据更易使用，并且它们往往能够去除数据中的噪声，通常作为预处理步骤，在算法应用前清洗数据。PCA可以从数据中识别主要特征，它通过沿着数据最大方差方向旋转坐标轴实现。如果要处理的数据过多无法放入内存，可以使用在线PCA分析，参考论文“Incremental Eigenanalysis for Classification”。</p>
</blockquote>
<hr>
<p>参考文献： 《机器学习实战 - 美Peter Harrington》</p>
<p>原创作品，允许转载，转载时无需告知，但请务必以超链接形式标明文章<a href="https://forec.github.io/2016/02/25/machinelearning13/">原始出处</a>(<a href="https://forec.github.io/2016/02/25/machinelearning13/">https://forec.github.io/2016/02/25/machinelearning13/</a>) 、作者信息（<a href="https://forec.github.io/">Forec</a>）和本声明。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://forec.github.io/2016/02/25/machinelearning13/" data-id="civ2lny3c002cv8ewiz6zj0fk" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Algorithms/">Algorithms</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/02/26/machinelearning14/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          机器学习笔记（Chapter 14 - SVD简化）
        
      </div>
    </a>
  
  
    <a href="/2016/02/24/machinelearning12/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">机器学习笔记（Chapter 12 - FP-growth算法）</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Code/">Code</a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataBase/">DataBase</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Language/">Language</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/OS/">OS</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Test/">Test</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机理论基础/">计算机理论基础</a><span class="category-list-count">6</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Access/">Access</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithms/">Algorithms</a><span class="tag-list-count">25</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVM/">CVM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Structures/">Data-Structures</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/">Docker</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Emacs/">Emacs</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Golang/">Golang</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/">Hadoop</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mistakes/">Mistakes</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OS/">OS</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Qt/">Qt</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Raspberry/">Raspberry</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sicp/">sicp</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/函数式编程/">函数式编程</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/图分割/">图分割</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/字符编码/">字符编码</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/线程/">线程</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/计算机组成与体系结构/">计算机组成与体系结构</a><span class="tag-list-count">6</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Access/" style="font-size: 10px;">Access</a> <a href="/tags/Algorithms/" style="font-size: 20px;">Algorithms</a> <a href="/tags/CVM/" style="font-size: 10px;">CVM</a> <a href="/tags/Data-Structures/" style="font-size: 14.29px;">Data-Structures</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/Emacs/" style="font-size: 10px;">Emacs</a> <a href="/tags/Golang/" style="font-size: 10px;">Golang</a> <a href="/tags/Hadoop/" style="font-size: 11.43px;">Hadoop</a> <a href="/tags/Mistakes/" style="font-size: 15.71px;">Mistakes</a> <a href="/tags/OS/" style="font-size: 15.71px;">OS</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Qt/" style="font-size: 10px;">Qt</a> <a href="/tags/Raspberry/" style="font-size: 10px;">Raspberry</a> <a href="/tags/Spark/" style="font-size: 10px;">Spark</a> <a href="/tags/sicp/" style="font-size: 10px;">sicp</a> <a href="/tags/函数式编程/" style="font-size: 12.86px;">函数式编程</a> <a href="/tags/图分割/" style="font-size: 11.43px;">图分割</a> <a href="/tags/字符编码/" style="font-size: 11.43px;">字符编码</a> <a href="/tags/机器学习/" style="font-size: 18.57px;">机器学习</a> <a href="/tags/线程/" style="font-size: 11.43px;">线程</a> <a href="/tags/计算机组成与体系结构/" style="font-size: 17.14px;">计算机组成与体系结构</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a><span class="archive-list-count">15</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">October 2015</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">September 2015</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">August 2015</a><span class="archive-list-count">4</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/11/02/cloud-virtual-machine-config/">CVM 操作记录</a>
          </li>
        
          <li>
            <a href="/2016/10/29/raspberry-settings/">Raspberry Pi 3 配置索引</a>
          </li>
        
          <li>
            <a href="/2016/10/08/haskell-fixit/">Fix in Haskell</a>
          </li>
        
          <li>
            <a href="/2016/10/03/co-occurrence-structure-capture/">Network Mining Based On Co-occurrence</a>
          </li>
        
          <li>
            <a href="/2016/09/27/duplicate-cantor/">Cantor Expansion With Duplicate Elements</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Forec<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>