<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习笔记（Chapter 07 - AdaBoost元算法） | Forec&#39;s Notes</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="元算法是对其他算法进行组合的一种方式。在做决定时，大家通常考虑吸取多个专家（分类算法）而不是一个专家的意见。当我们试图对样例数目不均衡的数据进行分类时，会遇到非均衡分类问题。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习笔记（Chapter 07 - AdaBoost元算法）">
<meta property="og:url" content="http://forec.github.io/2016/02/14/machinelearning7/index.html">
<meta property="og:site_name" content="Forec's Notes">
<meta property="og:description" content="元算法是对其他算法进行组合的一种方式。在做决定时，大家通常考虑吸取多个专家（分类算法）而不是一个专家的意见。当我们试图对样例数目不均衡的数据进行分类时，会遇到非均衡分类问题。">
<meta property="og:image" content="http://7xktmz.com1.z0.glb.clouddn.com/adaboost.png">
<meta property="og:updated_time" content="2016-10-03T15:37:44.580Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习笔记（Chapter 07 - AdaBoost元算法）">
<meta name="twitter:description" content="元算法是对其他算法进行组合的一种方式。在做决定时，大家通常考虑吸取多个专家（分类算法）而不是一个专家的意见。当我们试图对样例数目不均衡的数据进行分类时，会遇到非均衡分类问题。">
  
    <link rel="alternative" href="/atom.xml" title="Forec&#39;s Notes" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Forec&#39;s Notes</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://forec.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-machinelearning7" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/14/machinelearning7/" class="article-date">
  <time datetime="2016-02-14T14:06:25.000Z" itemprop="datePublished">2016-02-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/大数据/">大数据</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习笔记（Chapter 07 - AdaBoost元算法）
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>元算法是对其他算法进行组合的一种方式。在做决定时，大家通常考虑吸取多个专家（分类算法）而不是一个专家的意见。当我们试图对样例数目不均衡的数据进行分类时，会遇到非均衡分类问题。</p>
</blockquote>
<a id="more"></a>
<h1 id="基于数据集多重抽样的分类器"><a href="#基于数据集多重抽样的分类器" class="headerlink" title="基于数据集多重抽样的分类器"></a>基于数据集多重抽样的分类器</h1><ul>
<li>前面已经介绍了五种不同的分类算法，各有优缺点。我们可以将不同的分类器组合起来，这种组合结果被称为集成方法或者元算法。使用集成方法时会有许多形式，可以是不同算法的集合，也可以是同一算法在不同设置下的集成，还可以是数据集不同部分分配给不同分类器之后的集成。</li>
<li><strong>自举汇聚法</strong> （bootstrap aggregating，bagging）是从原始数据集选择S次后得到S个新数据集的技术。新数据集和原数据集大小相等，每个数据集都是通过在原始数据集中随机选择一个样本来进行替换得到的，因此有可能出现多次选择同一样本，所以这一行只允许新数据集中有重复的值，而原始数据集的某些值在新集合中则不再出现。当这S个数据集建好，将某个学习算法应用到每个数据集就得到了S个分类器，之后用这S个分类器分类，投票选择最终类别。其它先进的bagging方法有<strong>随机森林</strong>等，讨论材料见<a href="http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm。" target="_blank" rel="external">http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm。</a></li>
<li>boosting是一种与bagging类似的技术，无论在bo哦sting还是bagging中，分类器的类型都是一致的。但在前者中，不同的分类器是通过串行训练获得的，每个新分类器都根据已训练出的分类器的性能来训练。 <strong>boosting是通过集中关注被已有分类器错分的数据来获得新的分类器</strong> 。bagging中各个分类器的权重相等，而boosting中的分类器权重不等，代表其对应分类器在上一轮迭代中的成功度。</li>
<li><strong>AdaBoost流程</strong><ul>
<li>准备数据：依赖于使用的弱分类器类型，本章使用单层决策树，也可以使用任意分类器充当弱分类器。简单分类器作为弱分类器效果更好。</li>
<li>分析数据：任意方法。</li>
<li>训练算法：占据大部分时间，分类器将多次在同一数据集上训练弱分类器。</li>
<li>测试算法：计算分类错误率。</li>
<li>使用算法：二类分类器。</li>
</ul>
</li>
</ul>
<h1 id="基于错误提升分类器性能"><a href="#基于错误提升分类器性能" class="headerlink" title="基于错误提升分类器性能"></a>基于错误提升分类器性能</h1><ul>
<li>可以通过弱分类器和多个实例来构造一个强分类器，这里的“弱”意味着分类器的性能比随即猜测要略好，但不会好太多。AdaBoost是adaptive boosting（自适应boosting），过程如下。</li>
<li>训练数据集中的每个样本，并赋予其一个权重，这些权重构成了向量D。一开始这些权重都初始化为相等值。首先在训练数据上训练出一个弱分类器并计算该分类器的错误率，然后在同一数据集上再一次训练弱分类器。在分类器的第二次训练中，会重新调整每个样本的权重，其中上一次训练中分对的样本所占权重会降低，分错的样本所占样本权重升高。</li>
<li>AdaBoost为每个弱分类器设置一个权重α，这些α值根据每个弱分类器的错误率计算，错误率ε=未正确分类的样本数/所有的样本数目。α计算公式为<code>α=0.5*ln((1-ε)/ε)</code>。可见错误率下降，α上升。计算出α后，对权重向量D更新，如果某个样本被正确地分类，那么<code>D&#39; = D*e^(-α)/sum(D)</code>，如果某个样本被错分，那么<code>D&#39; = D*e^α/sum(D)</code>。</li>
<li>更新D后，AdaBoost进入下一轮迭代。其会不断重复训练和调整权重的过程，直到某次训练错误率为0，或者弱分类器达到用户指定的数量。</li>
</ul>
<h1 id="基于单层决策树构建弱分类器"><a href="#基于单层决策树构建弱分类器" class="headerlink" title="基于单层决策树构建弱分类器"></a>基于单层决策树构建弱分类器</h1><ul>
<li><p>单层决策树（决策树桩）是一种简单的决策树，仅基于单个特征来做决策，只有一次分裂过程，因此是一个树桩。</p>
</li>
<li><p>简单数据集加载 - adaboost.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadSimpData</span><span class="params">()</span>:</span></span><br><span class="line">	datMat = matrix([[ <span class="number">1.</span> , <span class="number">2.1</span> ],</span><br><span class="line">					 [ <span class="number">2.</span> , <span class="number">1.1</span> ],</span><br><span class="line">					 [ <span class="number">1.3</span>, <span class="number">1.</span>  ],</span><br><span class="line">					 [ <span class="number">1.</span> , <span class="number">1.</span>  ],</span><br><span class="line">					 [ <span class="number">2.</span> , <span class="number">1.</span>  ]])</span><br><span class="line">	classLabels = [<span class="number">1.0</span>, <span class="number">1.0</span>, -<span class="number">1.0</span>, -<span class="number">1.0</span>, <span class="number">1.0</span>]</span><br><span class="line">	<span class="keyword">return</span> datMat, classLabels</span><br></pre></td></tr></table></figure>
</li>
<li><p>建立最佳单层决策树</p>
<ul>
<li>将最小错误率minError设为+∞</li>
<li>对数据集中的每一个特征（一层循环）：</li>
<li>&nbsp;&nbsp;&nbsp;&nbsp;对每个步长（二层循环）：</li>
<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对每个不等号（三层循环）：</li>
<li>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;建立一棵单层决策树并利用加权数据集对他测试，如果错误率低于minError，就将当前的单层决策树设为最佳单层决策树</li>
<li>返回最佳单层决策树</li>
</ul>
</li>
<li><p>最佳单层决策树生成函数 - adaboost.py。下面包含两个函数，stumpClassify是通过阈值threshVal来确定类别，在阈值一边的数据分到类别-1，另一边分到类别+1。第二个函数buildStump遍历stumpClassify所有可能输入值，第一层循环遍历数据集所有特征，第二层遍历所有阈值，第三层遍历不等号。并找到数据集上最佳的单层决策树。之后返回一个bestStump字典，存乎了最优单层决策树的信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stumpClassify</span><span class="params">(dataMatrix, dimen, threshVal, threshIneq)</span>:</span></span><br><span class="line">	retArray = ones((shape(dataMatrix)[<span class="number">0</span>], <span class="number">1</span>))</span><br><span class="line">	<span class="keyword">if</span> threshIneq == <span class="string">'lt'</span>:</span><br><span class="line">		retArray[dataMatrix[:,dimen] &lt;= threshVal] = -<span class="number">1.0</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		retArray[dataMatrix[:,dimen] &gt; threshVal] = -<span class="number">1.0</span></span><br><span class="line">	<span class="keyword">return</span> retArray</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildStump</span><span class="params">(dataArr, classLabels, D)</span>:</span></span><br><span class="line">	dataMatrix = mat(dataArr); labelMat = mat(classLabels).T</span><br><span class="line">	m, n = shape(dataMatrix)</span><br><span class="line">	numSteps = <span class="number">10.0</span>; bestStump = &#123;&#125;; bestClasEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">	minError = inf</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">		rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();</span><br><span class="line">		stepSize = (rangeMax - rangeMin)/numSteps</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(-<span class="number">1</span>,int(numSteps)+<span class="number">1</span>):</span><br><span class="line">			<span class="keyword">for</span> inequal <span class="keyword">in</span> [<span class="string">'lt'</span>,<span class="string">'gt'</span>]:</span><br><span class="line">				threshVal = (rangeMin + float(j) * stepSize)</span><br><span class="line">				predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)</span><br><span class="line">				errArr = mat(ones((m,<span class="number">1</span>)))</span><br><span class="line">				errArr[predictedVals == labelMat] = <span class="number">0</span></span><br><span class="line">				weightedError = D.T * errArr</span><br><span class="line">				<span class="comment">#print "split: dim %d, thresh %.2f, thresh inequal: %s, the weighted error is %.3f" %\</span></span><br><span class="line">				<span class="comment">#	(i, threshVal, inequal, weightedError)</span></span><br><span class="line">				<span class="keyword">if</span> weightedError &lt; minError:</span><br><span class="line">					minError = weightedError</span><br><span class="line">					bestClasEst = predictedVals.copy()</span><br><span class="line">					bestStump[<span class="string">'dim'</span>] = i</span><br><span class="line">					bestStump[<span class="string">'thresh'</span>] = threshVal</span><br><span class="line">					bestStump[<span class="string">'ineq'</span>] = inequal</span><br><span class="line">	<span class="keyword">return</span> bestStump, minError, bestClasEst</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="完整AdaBoost算法"><a href="#完整AdaBoost算法" class="headerlink" title="完整AdaBoost算法"></a>完整AdaBoost算法</h1><ul>
<li><p>伪代码：对每次迭代</p>
<ul>
<li>利用buildStump找到最佳的单层决策树</li>
<li>将最佳单层决策树加入单层决策树数组</li>
<li>计算α</li>
<li>计算新的权重向量D</li>
<li>更新累计类别估计值</li>
<li>如果错误率为0.0则退出循环。</li>
</ul>
</li>
<li><p>下面是训练过程代码，输入参数为数据集、类别标签和迭代次数。D是概率分布向量，因此所有元素之和为1，因此初始全部为1/m。同时程序建立列向量aggClassEst记录每个数据点的类别估计累计值。程序中<code>max(error, 1e-16)</code>防止出现除零溢出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaBoostTrainDS</span><span class="params">(dataArr, classLabels, numIt = <span class="number">40</span>)</span>:</span></span><br><span class="line">	weakClassArr = []</span><br><span class="line">	m = shape(dataArr)[<span class="number">0</span>]</span><br><span class="line">	D = mat(ones((m,<span class="number">1</span>))/m)</span><br><span class="line">	aggClassEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(numIt):</span><br><span class="line">		bestStump, error, classEst = buildStump(dataArr, classLabels, D)</span><br><span class="line">		<span class="keyword">print</span> <span class="string">"D:"</span>, D.T</span><br><span class="line">		alpha = float(<span class="number">0.5</span>*log((<span class="number">1.0</span>-error)/max(error,<span class="number">1e-16</span>)))</span><br><span class="line">		bestStump[<span class="string">'alpha'</span>] = alpha</span><br><span class="line">		weakClassArr.append(bestStump)</span><br><span class="line">		<span class="keyword">print</span> <span class="string">"classEst "</span>, classEst.T</span><br><span class="line">		expon = multiply(-<span class="number">1</span>*alpha*mat(classLabels).T, classEst)</span><br><span class="line">		D = multiply(D, exp(expon))</span><br><span class="line">		D = D/D.sum()</span><br><span class="line">		aggClassEst += alpha*classEst</span><br><span class="line">		<span class="keyword">print</span> <span class="string">"aggClassEst: "</span>, aggClassEst.T</span><br><span class="line">		aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T, ones((m,<span class="number">1</span>)))</span><br><span class="line">		errorRate = aggErrors.sum() / m</span><br><span class="line">		<span class="keyword">print</span> <span class="string">"total error: "</span>, errorRate, <span class="string">"\n"</span></span><br><span class="line">		<span class="keyword">if</span> errorRate == <span class="number">0.0</span> : <span class="keyword">break</span></span><br><span class="line">	<span class="keyword">return</span> weakClassArr, aggClassEst</span><br></pre></td></tr></table></figure>
</li>
<li><p>分类：输入参数是待分类数据和分类器。遍历强分类器中的每个弱分类器，并通过stumpClassify得到每个分类器对某个类别的估计值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaClassify</span><span class="params">(datToClass, classifierArr)</span>:</span></span><br><span class="line">	dataMatrix = mat(datToClass)</span><br><span class="line">	m = shape(dataMatrix)[<span class="number">0</span>]</span><br><span class="line">	aggClassEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(len(classifierArr)):</span><br><span class="line">		classEst = stumpClassify(dataMatrix, classifierArr[i][<span class="string">'dim'</span>],\</span><br><span class="line">			classifierArr[i][<span class="string">'thresh'</span>], classifierArr[i][<span class="string">'ineq'</span>])</span><br><span class="line">		aggClassEst += classifierArr[i][<span class="string">'alpha'</span>] * classEst</span><br><span class="line">		<span class="keyword">print</span> aggClassEst</span><br><span class="line">	<span class="keyword">return</span> sign(aggClassEst)</span><br></pre></td></tr></table></figure>
</li>
<li><p>在疝气病马数据集上应用AdaBoost算法，通过loadDataSet读入数据，并进行分类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(filename)</span>:</span></span><br><span class="line">	numFeat = len(open(filename).readline().split(<span class="string">'\t'</span>))</span><br><span class="line">	dataMat = []; labelMat = []</span><br><span class="line">	fr = open(filename)</span><br><span class="line">	<span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">		lineArr = []</span><br><span class="line">		curLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> range(numFeat - <span class="number">1</span>):</span><br><span class="line">			lineArr.append(float(curLine[i]))</span><br><span class="line">		dataMat.append(lineArr)</span><br><span class="line">		labelMat.append(float(curLine[-<span class="number">1</span>]))</span><br><span class="line">	<span class="keyword">return</span> dataMat, labelMat</span><br><span class="line"></span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>datArr, labelArr = adaboost.loadDataSet(<span class="string">'horseColicTraining2.txt'</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>classifierArray = adaboost.adaBoostTrainDS(datArr, labelArr, <span class="number">10</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>testArr, testLabelArr = adaboost.loadDataSet(<span class="string">'horseColicTest2.txt'</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>prediction10 = adaboost.adaClassify(testArr, classifierArray)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>errArr = mat(ones((<span class="number">67</span>,<span class="number">1</span>)))</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>errArr[prediction10!=mat(testLabelArr).T].sum()</span><br></pre></td></tr></table></figure>
</li>
<li><p>错误率分析：当分类器数目从1到10000变化时，总测试错误率先达到一个 最小值，之后又上升。该现象称为过拟合。有文献表明，对于表现好的数据集（horseColicTest有30%数据缺失），AdaBoost的测试错误率会达到一个稳定之，并不会随着分类器增加而上升。</p>
</li>
</ul>
<h1 id="非均衡类问题和其他分类性能度量指标"><a href="#非均衡类问题和其他分类性能度量指标" class="headerlink" title="非均衡类问题和其他分类性能度量指标"></a>非均衡类问题和其他分类性能度量指标</h1><blockquote>
<p>之前的分类都假设所有分类代价一样，但实际上将马归类为死或者活的代价不同，假如分类器只有80%正确率，将一匹本能存活的马判定为安乐死，损失会更大。</p>
</blockquote>
<ul>
<li><strong>混淆矩阵</strong>：列方向为预测结果，行方向为实际结果，如果除了对角线，其他元素都是0，那么将是一个完美的分类器。</li>
<li>对于二类问题：如果将正例判为正例则产生真阳例（TP），将反例正确判为反例则产生真阴例（TN），将正例错判为反例，则产生假阴例（FN），将反例错判为正例称为假阳例（FP）。正确率=TP/(TP+FP)，召回率=TP/(TP+FN)。在高召回率的分类器重，真正判错的正例数目并不多。我们可以很容易构造一个高准确率或者高召回率的分类器，但很难保证两者同时成立。</li>
<li>ROC曲线：横轴为假阳率=FP/(FP+TN)，纵轴是真阳率=TP/(TP+FN)。ROC曲线给出的是当阈值变化时假阳率和真阳率变化的情况。左下角点对应所有样例判为反例，右上角对应所有样例判为正例。理想情况下，最佳分类器应尽可能处于左上角。另一个指标是ROC曲线下的面积AUC，代表了分类器的平均性能值。完美分类器的AUC=1.0，随即猜测的AUC=0.5。</li>
<li><p>创建ROC曲线。首先将分类样例按照预测强度排序，强度高的分为正例，低的判为反例。下面为创建ROC曲线的代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotROC</span><span class="params">(predStrengths, classLabels)</span>:</span></span><br><span class="line">	<span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">	cur = (<span class="number">1.0</span>, <span class="number">1.0</span>)</span><br><span class="line">	ySum = <span class="number">0.0</span></span><br><span class="line">	numPosClas = sum(array(classLabels) == <span class="number">1.0</span>)</span><br><span class="line">	yStep = <span class="number">1</span>/float(numPosClas)</span><br><span class="line">	xStep = <span class="number">1</span>/float(len(classLabels) - numPosClas)</span><br><span class="line">	sortedIndicies = predStrengths.argsort()</span><br><span class="line">	fig = plt.figure()</span><br><span class="line">	fig.clf()</span><br><span class="line">	ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">	<span class="keyword">for</span> index <span class="keyword">in</span> sortedIndicies.tolist()[<span class="number">0</span>]:</span><br><span class="line">		<span class="keyword">if</span> classLabels[index] == <span class="number">1.0</span>:</span><br><span class="line">			delX = <span class="number">0</span>; delY = yStep;</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			delX = xStep; delY = <span class="number">0</span>;</span><br><span class="line">			ySum += cur[<span class="number">1</span>]</span><br><span class="line">		ax.plot([cur[<span class="number">0</span>], cur[<span class="number">0</span>]-delX], [cur[<span class="number">1</span>], cur[<span class="number">1</span>] - delY], c= <span class="string">'b'</span>)</span><br><span class="line">		cur = (cur[<span class="number">0</span>] - delX, cur[<span class="number">1</span>] - delY)</span><br><span class="line">	ax.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>],<span class="string">'b--'</span>)</span><br><span class="line">	plt.xlabel(<span class="string">'False Positive Rate'</span>); plt.ylabel(<span class="string">'True Positive Rate'</span>)</span><br><span class="line">	plt.title(<span class="string">'ROC curve for AdaBoost Horse Colic Detection System'</span>)</span><br><span class="line">	ax.axis([<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">	plt.show()</span><br><span class="line">	<span class="keyword">print</span> <span class="string">"the Area Under the Curve is: "</span>, ySum * xStep</span><br></pre></td></tr></table></figure>
</li>
<li><p>生成图像如下<img src="http://7xktmz.com1.z0.glb.clouddn.com/adaboost.png" width="500px"></p>
</li>
<li><p><strong>代价敏感</strong>的学习：选择具有最小期望代价而不是最大概率的类别作为最后的结果。</p>
</li>
<li>数据抽样方法：欠抽样和过抽样。欠抽样指删除部分样例，过抽样指复制部分样例。对于罕见类别，要尽量保留更多信息，通常选择离决策边界较远的样例删除。另一种策略是使用反例类别的欠抽样和正例类别的过抽样结合。</li>
</ul>
<h1 id="AdaBoost元算法总结"><a href="#AdaBoost元算法总结" class="headerlink" title="AdaBoost元算法总结"></a>AdaBoost元算法总结</h1><blockquote>
<p>元算法过多个分类器组合，可以减轻单分类器的不足。AdaBoost函数可以应用于任何分类器，只要该分类器可以处理加权数据。非均衡分类问题指在分类器训练时正例数目和反例数目不等或者相差很大，或者错分正例和反例代价不同时产生。</p>
</blockquote>
<hr>
<p>参考文献： 《机器学习实战 - 美Peter Harrington》</p>
<p>原创作品，允许转载，转载时无需告知，但请务必以超链接形式标明文章<a href="https://forec.github.io/2016/02/14/machinelearning7/">原始出处</a>(<a href="https://forec.github.io/2016/02/14/machinelearning7/">https://forec.github.io/2016/02/14/machinelearning7/</a>) 、作者信息（<a href="https://forec.github.io/">Forec</a>）和本声明。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://forec.github.io/2016/02/14/machinelearning7/" data-id="civ2lny2x001sv8ewahjaf6k8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Algorithms/">Algorithms</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/02/18/machinelearning8/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          机器学习笔记（Chapter 08 - 回归）
        
      </div>
    </a>
  
  
    <a href="/2016/02/13/functional-thinking/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">《函数式编程思维》笔记</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Code/">Code</a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataBase/">DataBase</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Language/">Language</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/OS/">OS</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Test/">Test</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机理论基础/">计算机理论基础</a><span class="category-list-count">6</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Access/">Access</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithms/">Algorithms</a><span class="tag-list-count">25</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVM/">CVM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Structures/">Data-Structures</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/">Docker</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Emacs/">Emacs</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Golang/">Golang</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/">Hadoop</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mistakes/">Mistakes</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OS/">OS</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Qt/">Qt</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Raspberry/">Raspberry</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sicp/">sicp</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/函数式编程/">函数式编程</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/图分割/">图分割</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/字符编码/">字符编码</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/线程/">线程</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/计算机组成与体系结构/">计算机组成与体系结构</a><span class="tag-list-count">6</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Access/" style="font-size: 10px;">Access</a> <a href="/tags/Algorithms/" style="font-size: 20px;">Algorithms</a> <a href="/tags/CVM/" style="font-size: 10px;">CVM</a> <a href="/tags/Data-Structures/" style="font-size: 14.29px;">Data-Structures</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/Emacs/" style="font-size: 10px;">Emacs</a> <a href="/tags/Golang/" style="font-size: 10px;">Golang</a> <a href="/tags/Hadoop/" style="font-size: 11.43px;">Hadoop</a> <a href="/tags/Mistakes/" style="font-size: 15.71px;">Mistakes</a> <a href="/tags/OS/" style="font-size: 15.71px;">OS</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Qt/" style="font-size: 10px;">Qt</a> <a href="/tags/Raspberry/" style="font-size: 10px;">Raspberry</a> <a href="/tags/Spark/" style="font-size: 10px;">Spark</a> <a href="/tags/sicp/" style="font-size: 10px;">sicp</a> <a href="/tags/函数式编程/" style="font-size: 12.86px;">函数式编程</a> <a href="/tags/图分割/" style="font-size: 11.43px;">图分割</a> <a href="/tags/字符编码/" style="font-size: 11.43px;">字符编码</a> <a href="/tags/机器学习/" style="font-size: 18.57px;">机器学习</a> <a href="/tags/线程/" style="font-size: 11.43px;">线程</a> <a href="/tags/计算机组成与体系结构/" style="font-size: 17.14px;">计算机组成与体系结构</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a><span class="archive-list-count">15</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">October 2015</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">September 2015</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">August 2015</a><span class="archive-list-count">4</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/11/02/cloud-virtual-machine-config/">CVM 操作记录</a>
          </li>
        
          <li>
            <a href="/2016/10/29/raspberry-settings/">Raspberry Pi 3 配置索引</a>
          </li>
        
          <li>
            <a href="/2016/10/08/haskell-fixit/">Fix in Haskell</a>
          </li>
        
          <li>
            <a href="/2016/10/03/co-occurrence-structure-capture/">Network Mining Based On Co-occurrence</a>
          </li>
        
          <li>
            <a href="/2016/09/27/duplicate-cantor/">Cantor Expansion With Duplicate Elements</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Forec<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>